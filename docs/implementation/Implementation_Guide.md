# RAGé¡¹ç›®é‡æ„å®æ–½æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

#### 1. ç³»ç»Ÿè¦æ±‚
- Python 3.9+
- Git
- Docker (å¯é€‰ï¼Œç”¨äºå®¹å™¨åŒ–éƒ¨ç½²)
- è¶³è¿‡8GB RAMï¼ˆç”¨äºAIæ¨¡å‹æœåŠ¡ï¼‰

#### 2. å®‰è£…uvåŒ…ç®¡ç†å™¨
```bash
# Windows (PowerShell)
Invoke-WebRequest -Uri "https://astral.sh/uv/install.ps1" -OutFile "install.ps1"
.\install.ps1

# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### 3. å…‹éš†é¡¹ç›®
```bash
git clone <repository-url>
cd complex_rag
```

#### 4. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
```bash
uv venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows

uv pip install -e .
```

## ğŸ“‹ å®æ–½é˜¶æ®µ

### é˜¶æ®µ1ï¼šåŸºç¡€æ¶æ„æ­å»ºï¼ˆ2-3å‘¨ï¼‰

#### 1.1 åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
```bash
# é¡¹ç›®åŸºç¡€ç›®å½•å·²ç»å­˜åœ¨ï¼ŒéªŒè¯å®Œæ•´æ€§
ls -la
```

#### 1.2 é…ç½®åˆ†ç¦»å¼æœåŠ¡é…ç½®
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶
ls config/services/
ls config/ragflow_configs/
```

#### 1.3 éªŒè¯å¤šç§Ÿæˆ·æ•°æ®æ¨¡å‹
```python
# æ£€æŸ¥SQLAlchemyæ¨¡å‹æ˜¯å¦åˆ›å»º
from infrastructure.database.models import BaseModel, TenantBaseModel

# éªŒè¯æ¨¡å‹ç»“æ„
from infrastructure.database.models.user_model import User
from infrastructure.database.models.tenant_model import Tenant
from infrastructure.database.models.knowledge_model import KnowledgeBase
```

#### 1.4 æµ‹è¯•æ–‡ä»¶æ¥æºæ£€æµ‹å™¨
```python
# åˆ›å»ºæµ‹è¯•æ–‡ä»¶
python -c "
from document_parser.strategies.source_detector import FileSourceDetector

# æµ‹è¯•æ¥æºæ£€æµ‹
test_cases = [
    {'url': 'https://example.com', 'expected': FileSource.WEB_DOCUMENT},
    {'file_extension': '.pdf', 'expected': FileSource.OFFICE_DOCUMENT},
    {'file_extension': '.json', 'expected': FileSource.STRUCTURED_DATA}
]

for case in test_cases:
    detected = FileSourceDetector.detect_source(case)
    print(f"Input: {case}, Detected: {detected}, Expected: {case['expected']}")
"
```

### é˜¶æ®µ2ï¼šæ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆ3-4å‘¨ï¼‰

#### 2.1 é›†æˆRAGFlowè§†è§‰è¯†åˆ«æ¨¡å—

**æ­¥éª¤1ï¼šå¤åˆ¶RAGFlowè§†è§‰è¯†åˆ«ä»£ç **
```bash
# åˆ›å»ºè§†è§‰è¯†åˆ«ç›®å½•
mkdir -p document_parser/vision

# ä»RAGFlowå¤åˆ¶æ ¸å¿ƒæ–‡ä»¶ï¼ˆéœ€è¦æ‰‹åŠ¨æ“ä½œï¼‰
# å¤åˆ¶ä»¥ä¸‹æ–‡ä»¶åˆ° document_parser/vision/ï¼š
# - ocr.py
# - recognizer.py
# - layout_recognizer.py
# - table_structure_recognizer.py
# - operators.py
# - postprocess.py
```

**æ­¥éª¤2ï¼šé€‚é…è§†è§‰è¯†åˆ«æ¨¡å—**
```python
# document_parser/vision/__init__.py
from .ocr import OCR
from .recognizer import Recognizer
from .layout_recognizer import LayoutRecognizer
from .table_structure_recognizer import TableStructureRecognizer

# é€‚é…å¼‚æ­¥æ¶æ„
class AsyncOCR:
    async def extract_text(self, image_path: str) -> str:
        # é€‚é…RAGFlowåŒæ­¥ä»£ç åˆ°å¼‚æ­¥
        # å®ç°å¼‚æ­¥è°ƒç”¨é€»è¾‘
        pass
```

#### 2.2 å®ç°æ–‡ä»¶æ¥æºä¸“ç”¨å¤„ç†å™¨

**æ­¥éª¤1ï¼šåˆ›å»ºæ¥æºå¤„ç†å™¨åŸºç¡€ç±»**
```python
# document_parser/source_handlers/__init__.py
from abc import ABC, abstractmethod

class DocumentHandler(ABC):
    @abstractmethod
    async def handle(self, file_info: dict) -> dict:
        pass

    @abstractmethod
    def supports(self, file_source: FileSource) -> bool:
        pass
```

**æ­¥éª¤2ï¼šå®ç°web_documentså¤„ç†å™¨**
```python
# document_parser/source_handlers/web_documents/__init__.py
from ..base import DocumentHandler
from ...parsers.html_parser import HTMLParser
from ...parsers.markdown_parser import MarkdownParser

class WebDocumentHandler(DocumentHandler):
    def supports(self, file_source: FileSource) -> bool:
        return file_source == FileSource.WEB_DOCUMENT

    async def handle(self, file_info: dict) -> dict:
        file_extension = file_info.get('file_extension', '').lower()

        if file_extension == '.html':
            parser = HTMLParser()
        elif file_extension == '.md':
            parser = MarkdownParser()
        else:
            raise ValueError(f"Unsupported web document type: {file_extension}")

        return await parser.parse(file_info['file_path'])
```

**æ­¥éª¤3ï¼šå®ç°office_documentså¤„ç†å™¨**
```python
# document_parser/source_handlers/office_documents/pdf_handler.py
from ...parsers.ragflow_pdf_parser import RAGFlowPdfParser
from ...vision import OCR, LayoutRecognizer

class PDFHandler(DocumentHandler):
    def supports(self, file_source: FileSource) -> bool:
        return file_source == FileSource.OFFICE_DOCUMENT

    async def handle(self, file_info: dict) -> dict:
        # ä½¿ç”¨RAGFlow PDFè§£æå™¨
        parser = RAGFlowPdfParser()

        # å¤„ç†PDFæ–‡æ¡£
        result = parser(file_info['file_path'], binary=file_info.get('binary'))

        return {
            'content': result,
            'metadata': {
                'pages': len(result),
                'file_type': 'pdf',
                'source': 'office_document'
            }
        }
```

#### 2.3 å®ç°å¤„ç†ç­–ç•¥é€‰æ‹©å™¨
```python
# document_parser/strategies/strategy_selector.py
from enum import Enum
from typing import Dict, Any

class FileSource(Enum):
    WEB_DOCUMENT = "web_document"
    OFFICE_DOCUMENT = "office_document"
    SCANNED_DOCUMENT = "scanned_document"
    STRUCTURED_DATA = "structured_data"
    CODE_REPOSITORY = "code_repository"

class ProcessingStrategy(BaseModel):
    file_source: FileSource
    parser_type: str
    chunk_size: int = 1000
    chunk_overlap: int = 200
    embedding_model: str = "qwen3_embedding"
    rerank_enabled: bool = True

class StrategySelector:
    def __init__(self):
        self.strategies = {
            FileSource.WEB_DOCUMENT: ProcessingStrategy(
                file_source=FileSource.WEB_DOCUMENT,
                parser_type="html_parser",
                chunk_size=800,
                chunk_overlap=150,
                embedding_model="qwen3_embedding",
                rerank_enabled=True
            ),
            FileSource.OFFICE_DOCUMENT: ProcessingStrategy(
                file_source=FileSource.OFFICE_DOCUMENT,
                parser_type="pdf_parser",
                chunk_size=1000,
                chunk_overlap=200,
                embedding_model="qwen3_embedding",
                rerank_enabled=True
            ),
            # ... å…¶ä»–ç­–ç•¥é…ç½®
        }

    def get_strategy(self, file_source: FileSource) -> ProcessingStrategy:
        return self.strategies.get(file_source)
```

#### 2.4 å®ç°æ•°æ®åº“è¿æ¥å’ŒåŸºç¡€æ¨¡å‹

**æ­¥éª¤1ï¼šé…ç½®MySQLè¿æ¥**
```python
# config/services/db_config.py
from pydantic import BaseSettings

class DatabaseConfig(BaseSettings):
    MYSQL_HOST: str = "localhost"
    MYSQL_PORT: int = 3306
    MYSQL_DB: str = "rag_system"
    MYSQL_USER: str = "rag_user"
    MYSQL_PASSWORD: str = "rag_password"
    MYSQL_CHARSET: str = "utf8mb4"

    class Config:
        env_file = ".env"

# infrastructure/database/implementations/mysql_client.py
from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine

class MySQLClient:
    def __init__(self, config: DatabaseConfig):
        self.config = config
        self.engine = create_async_engine(
            f"mysql+aiomysql://{config.MYSQL_USER}:{config.MYSQL_PASSWORD}@"
            f"{config.MYSQL_HOST}:{config.MYSQL_PORT}/{config.MYSQL_DB}",
            echo=False,
            charset=config.MYSQL_CHARSET
        )

    async def get_session(self) -> AsyncSession:
        async with self.engine.begin() as conn:
            return AsyncSession(conn)
```

**æ­¥éª¤2ï¼šå®ç°åŸºç¡€æ•°æ®æ¨¡å‹**
```python
# infrastructure/database/models/base_model.py
from sqlalchemy import Column, String, BigInteger, DateTime, Boolean
from sqlalchemy.ext.declarative import declarative_base
import uuid
from datetime import datetime

Base = declarative_base()

class BaseModel(Base):
    __abstract__ = True

    id = Column(String(32), primary_key=True, default=lambda: uuid.uuid4().hex)
    create_time = Column(BigInteger, nullable=False, index=True, default=int(datetime.now().timestamp()))
    create_date = Column(DateTime, nullable=False, index=True, default=datetime.now)
    update_time = Column(BigInteger, nullable=True, index=True)
    update_date = Column(DateTime, nullable=True, index=True)
    status = Column(String(1), default="1")  # "1"=æ­£å¸¸, "0"=åˆ é™¤

    def update_timestamp(self):
        self.update_time = int(datetime.now().timestamp())
        self.update_date = datetime.now()

# infrastructure/database/models/tenant_base_model.py
from .base_model import BaseModel

class TenantBaseModel(BaseModel):
    __abstract__ = True

    tenant_id = Column(String(32), nullable=False, index=True, comment="ç§Ÿæˆ·ID")
```

### é˜¶æ®µ3ï¼šé«˜çº§åŠŸèƒ½å®ç°ï¼ˆ2-3å‘¨ï¼‰

#### 3.1 é›†æˆRAGFlow GraphRAGæ¨¡å—

**æ­¥éª¤1ï¼šå¤åˆ¶RAGFlow GraphRAGä»£ç **
```bash
# åˆ›å»ºGraphRAGç›®å½•
mkdir -p core_rag/graph_rag/general core_rag/graph_rag/light

# ä»RAGFlowå¤åˆ¶æ ¸å¿ƒæ–‡ä»¶ï¼ˆéœ€è¦æ‰‹åŠ¨æ“ä½œï¼‰
# core_rag/graph_rag/general/
# core_rag/graph_rag/light/
```

**æ­¥éª¤2ï¼šå®ç°GraphRAGæœåŠ¡**
```python
# core_rag/graph_rag/services/graph_service.py
from .general.extraction import EntityExtraction
from .light.extraction import LightExtraction
from .search.kg_search import KGSearch

class GraphRAGService:
    def __init__(self):
        self.general_extractor = EntityExtraction()
        self.light_extractor = LightExtraction()
        self.kg_search = KGSearch()

    async def process_document(self, text: str, mode: str = "general") -> dict:
        if mode == "general":
            # ä½¿ç”¨Generalæ¨¡å¼ï¼ˆå¤šè½®æŠ½å–ï¼‰
            return await self.general_extractor.extract(text)
        elif mode == "light":
            # ä½¿ç”¨Lightæ¨¡å¼ï¼ˆå•æ¬¡æŠ½å–ï¼‰
            return await self.light_extractor.extract(text)
        else:
            raise ValueError(f"Unsupported mode: {mode}")
```

#### 3.2 å®ç°Mem0ä¸Šä¸‹æ–‡å¤„ç†

**æ­¥éª¤1ï¼šå®‰è£…å’Œé…ç½®Mem0**
```bash
# å®‰è£…Mem0
uv add mem0ai
```

**æ­¥éª¤2ï¼šå®ç°Mem0æœåŠ¡**
```python
# core_rag/memory/implementations/mem0_memory.py
import mem0
from ..interfaces.memory_interface import MemoryInterface

class Mem0Memory(MemoryInterface):
    def __init__(self, api_key: str):
        self.client = mem0.Memory()
        self.api_key = api_key

    async def store_memory(self, messages: list, user_id: str, metadata: dict = None) -> str:
        # å­˜å‚¨å¯¹è¯è®°å¿†
        result = self.client.add(
            messages=messages,
            user_id=user_id,
            metadata=metadata or {}
        )
        return result.get("id")

    async def search_memory(self, query: str, user_id: str, limit: int = 5) -> list:
        # æœç´¢ç›¸å…³è®°å¿†
        results = self.client.search(
            query=query,
            user_id=user_id,
            limit=limit
        )
        return results.get("results", [])
```

#### 3.3 å®ç°LangGraphå¬å›ç»„ä»¶

**æ­¥éª¤1ï¼šå®‰è£…LangGraph**
```bash
# å®‰è£…LangGraph
uv add langgraph
```

**æ­¥éª¤2ï¼šå®ç°å¬å›èŠ‚ç‚¹**
```python
# core_rag/langgraph/nodes/vector_node.py
from langgraph.graph import State
from ..interfaces.vector_retriever import VectorRetrieverInterface

class VectorNode:
    def __init__(self, retriever: VectorRetrieverInterface):
        self.retriever = retriever

    async def __call__(self, state: State) -> State:
        # æ‰§è¡Œå‘é‡æ£€ç´¢
        query = state["query"]
        results = await self.retriever.retrieve(query)
        state["vector_results"] = results
        return state

# core_rag/langgraph/nodes/keyword_node.py
# ç±»ä¼¼å®ç°å…³é”®è¯æ£€ç´¢èŠ‚ç‚¹

# core_rag/langgraph/nodes/entity_node.py
# ç±»ä¼¼å®ç°å®ä½“æ£€ç´¢èŠ‚ç‚¹
```

**æ­¥éª¤3ï¼šå®ç°å¬å›å·¥ä½œæµ**
```python
# core_rag/langgraph/workflows/retrieval_workflow.py
from langgraph.graph import StateGraph, START, END
from ..nodes.vector_node import VectorNode
from ..nodes.keyword_node import KeywordNode
from ..nodes.entity_node import EntityNode

class RetrievalWorkflow:
    def __init__(self):
        self.workflow = StateGraph(State)

        # æ·»åŠ èŠ‚ç‚¹
        self.workflow.add_node("vector_retrieval", VectorNode(retriever))
        self.workflow.add_node("keyword_retrieval", KeywordNode(retriever))
        self.workflow.add_node("entity_retrieval", EntityNode(retriever))

        # è®¾ç½®è¾¹
        self.workflow.add_edge(START, "vector_retrieval")
        self.workflow.add_edge("vector_retrieval", "keyword_retrieval")
        self.workflow.add_edge("keyword_retrieval", "entity_retrieval")
        self.workflow.add_edge("entity_retrieval", END)

    async def run(self, initial_state: dict) -> dict:
        runnable = self.workflow.compile()
        state = initial_state
        result = await runnable.ainvoke(state)
        return result
```

### é˜¶æ®µ4ï¼šæµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰

#### 4.1 ç¼–å†™å•å…ƒæµ‹è¯•

**ç¤ºä¾‹ï¼šæµ‹è¯•æ–‡ä»¶æ¥æºæ£€æµ‹å™¨**
```python
# tests/unit/test_source_detector.py
import pytest
from document_parser.strategies.source_detector import FileSourceDetector

class TestFileSourceDetector:
    def test_detect_web_document(self):
        file_info = {"url": "https://example.com"}
        result = FileSourceDetector.detect_source(file_info)
        assert result == FileSource.WEB_DOCUMENT

    def test_detect_office_document(self):
        file_info = {"file_extension": ".pdf"}
        result = FileSourceDetector.detect_source(file_info)
        assert result == FileSource.OFFICE_DOCUMENT
```

**ç¤ºä¾‹ï¼šæµ‹è¯•æ–‡æ¡£å¤„ç†å™¨**
```python
# tests/unit/test_document_handlers.py
import pytest
from document_parser.source_handlers.office_documents.pdf_handler import PDFHandler
from document_parser.strategies.source_detector import FileSource

class TestPDFHandler:
    @pytest.fixture
    def pdf_handler(self):
        return PDFHandler()

    def test_supports_pdf(self, pdf_handler):
        assert pdf_handler.supports(FileSource.OFFICE_DOCUMENT)
        assert not pdf_handler.supports(FileSource.WEB_DOCUMENT)

    @pytest.mark.asyncio
    async def test_handle_pdf_file(self, pdf_handler):
        # åˆ›å»ºæµ‹è¯•PDFæ–‡ä»¶
        # æµ‹è¯•PDFå¤„ç†é€»è¾‘
        pass
```

#### 4.2 å®ç°å¼€å‘è°ƒè¯•å·¥å…·

**ä¸€é”®æ¸…ç†æ•°æ®è„šæœ¬**
```python
# scripts/clear_all_data.py
import asyncio
from infrastructure.database.mysql_client import MySQLClient
from infrastructure.database.milvus_client import MilvusClient
from infrastructure.database.es_client import ElasticsearchClient
from infrastructure.cache.redis_client import RedisClient

async def clear_all_data():
    print("å¼€å§‹æ¸…ç†æ‰€æœ‰æ•°æ®...")

    # æ¸…ç†MySQLæ•°æ®
    mysql_client = MySQLClient(config.db_config)
    await mysql_client.clear_all_tables()
    print("âœ… MySQLæ•°æ®æ¸…ç†å®Œæˆ")

    # æ¸…ç†Milvusæ•°æ®
    milvus_client = MilvusClient(config.milvus_config)
    await milvus_client.clear_all_collections()
    print("âœ… Milvusæ•°æ®æ¸…ç†å®Œæˆ")

    # æ¸…ç†Elasticsearchæ•°æ®
    es_client = ElasticsearchClient(config.es_config)
    await es_client.clear_all_indices()
    print("âœ… Elasticsearchæ•°æ®æ¸…ç†å®Œæˆ")

    # æ¸…ç†Redisç¼“å­˜
    redis_client = RedisClient(config.redis_config)
    await redis_client.clear_all_data()
    print("âœ… Redisç¼“å­˜æ¸…ç†å®Œæˆ")

    print("ğŸ‰ æ‰€æœ‰æ•°æ®æ¸…ç†å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(clear_all_data())
```

**æœåŠ¡å¯åŠ¨è„šæœ¬**
```python
# scripts/start_services.py
import asyncio
import uvicorn
from api.main import app as api_app
from rag_service.app import app as rag_app

async def start_api_service():
    config = uvicorn.Config(
        api_app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
    await uvicorn.serve(config)

async def start_rag_service():
    config = uvicorn.Config(
        rag_app,
        host="0.0.0.0",
        port=8001,
        workers=1,  # å•è¿›ç¨‹æ¨¡å¼
        log_level="info"
    )
    await uvicorn.serve(config)

async def main():
    print("ğŸš€ å¯åŠ¨æœåŠ¡...")

    # å¹¶å‘å¯åŠ¨ä¸¤ä¸ªæœåŠ¡
    await asyncio.gather(
        start_api_service(),
        start_rag_service()
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡é…ç½®
åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
# æ•°æ®åº“é…ç½®
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_DB=rag_system
MYSQL_USER=rag_user
MYSQL_PASSWORD=your_password
MYSQL_CHARSET=utf8mb4

# å‘é‡æ•°æ®åº“é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION_NAME=document_embeddings

# Elasticsearché…ç½®
ES_HOST=localhost
ES_PORT=9200
ES_INDEX_NAME=document_search

# Redisé…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# AIæ¨¡å‹é…ç½®
QWEN3_API_KEY=your_qwen3_api_key
OPENAI_API_KEY=your_openai_api_key

# Mem0é…ç½®
MEM0_API_KEY=your_mem0_api_key

# MinIOé…ç½®
MINIO_HOST=localhost
MINIO_PORT=9000
MINIO_ACCESS_KEY=your_access_key
MINIO_SECRET_KEY=your_secret_key
MINIO_BUCKET_NAME=rag-documents
```

### æœåŠ¡é…ç½®ç¤ºä¾‹

**APIæœåŠ¡é…ç½® (config/services/api_config.py)**
```python
from pydantic import BaseSettings

class APIConfig(BaseSettings):
    # æœåŠ¡å™¨é…ç½®
    SERVER_HOST: str = "0.0.0.0"
    SERVER_PORT: int = 8000
    DEBUG: bool = False

    # CORSé…ç½®
    CORS_ORIGINS: list = ["*"]
    ALLOW_CREDENTIALS: bool = True

    # APIé…ç½®
    API_V1_PREFIX: str = "/api/v1"

    # å“åº”é…ç½®
    DEFAULT_RESPONSE_CLASS: str = "json"
    MAX_REQUEST_SIZE: int = 16 * 1024 * 1024  # 16MB
```

**RAGæœåŠ¡é…ç½® (config/services/rag_service_config.py)**
```python
from pydantic import BaseSettings

class RAGServiceConfig(BaseSettings):
    # æœåŠ¡å™¨é…ç½®
    SERVER_HOST: str = "0.0.0.0"
    SERVER_PORT: int = 8001
    WORKERS: int = 1  # å•è¿›ç¨‹æ¨¡å¼

    # AIæ¨¡å‹é…ç½®
    DEFAULT_LLM_MODEL: str = "qwen3:latest"
    DEFAULT_EMBEDDING_MODEL: str = "qwen3-embedding:latest"
    DEFAULT_RERANK_MODEL: str = "qwen3-reranker:latest"

    # OpenAIå…¼å®¹é…ç½®
    OPENAI_API_BASE: str = "https://api.openai.com/v1"
    OPENAI_API_KEY: str = "your_openai_key"

    # å¤„ç†é…ç½®
    MAX_CONCURRENT_REQUESTS: int = 10
    REQUEST_TIMEOUT: int = 30
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€
mysql -h localhost -u rag_user -p

# æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
telnet localhost 3306

# æŸ¥çœ‹MySQLé”™è¯¯æ—¥å¿—
tail -f /var/log/mysql/error.log
```

#### 2. å‘é‡æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥MilvusæœåŠ¡çŠ¶æ€
python -c "
from pymilvus import connections
connections.connect('default', host='localhost', port='19530')
print('Milvusè¿æ¥æˆåŠŸ')
"

# æ£€æŸ¥Milvusé›†åˆçŠ¶æ€
# ä½¿ç”¨Milvuså®¢æˆ·ç«¯å·¥å…·
```

#### 3. å†…å­˜ä¸è¶³
```bash
# æ£€æŸ¥ç³»ç»Ÿå†…å­˜ä½¿ç”¨
free -h
htop

# è°ƒæ•´Pythonå†…å­˜é™åˆ¶ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
export PYTHONMALLOC=max(100000000, $PYTHONMALLOC)
```

#### 4. æ¨¡å‹åŠ è½½å¤±è´¥
```python
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
import os
from pathlib import Path

model_path = Path("assets/models/llm_models")
if model_path.exists():
    print(f"æ¨¡å‹ç›®å½•å­˜åœ¨: {model_path}")
    print(f"æ¨¡å‹æ–‡ä»¶: {list(model_path.glob('*'))}")
else:
    print("æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·ä¸‹è½½æ¨¡å‹")
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# æˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®
LOG_LEVEL=DEBUG
```

#### 2. ä½¿ç”¨è°ƒè¯•å·¥å…·
```python
# æ·»åŠ æ–­ç‚¹
import pdb; pdb.set_trace()

# ä½¿ç”¨IPythonè°ƒè¯•
import IPython; IPython.embed()
```

#### 3. æ€§èƒ½åˆ†æ
```python
import cProfile
import pstats

# åˆ†æå‡½æ•°æ€§èƒ½
cProfile.run('your_function()')
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åº“ä¼˜åŒ–
- åœ¨tenant_idä¸Šå»ºç«‹å¤åˆç´¢å¼•
- ä½¿ç”¨è¿æ¥æ± ç®¡ç†è¿æ¥
- å®ç°æŸ¥è¯¢ç»“æœç¼“å­˜

### 2. å‘é‡æ£€ç´¢ä¼˜åŒ–
- é¢„è®¡ç®—å¹¶ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢çš„å‘é‡
- æ‰¹é‡å¤„ç†å‘é‡è®¡ç®—
- è°ƒæ•´å‘é‡ç»´åº¦å’Œç´¢å¼•å‚æ•°

### 3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
- å®ç°å¤šçº§ç¼“å­˜ï¼ˆå†…å­˜+Redisï¼‰
- è®¾ç½®åˆç†çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
- å®ç°ç¼“å­˜é¢„çƒ­æœºåˆ¶

## ğŸ“š éƒ¨ç½²æŒ‡å—

### Dockeréƒ¨ç½²ï¼ˆæ¨èï¼‰

#### 1. æ„å»ºDockeré•œåƒ
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…uv
COPY pyproject.toml .
RUN uv venv
RUN uv pip install -e .

# å¤åˆ¶æºä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app/.venv/bin
ENV PATH=/app/.venv/bin:$PATH

# æš´éœ²ç«¯å£
EXPOSE 8000 8001

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 2. Docker Composeé…ç½®
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MYSQL_HOST=mysql
      - REDIS_HOST=redis
    depends_on:
      - mysql
      - redis

  rag-service:
    build: .
    ports:
      - "8001:8001"
    environment:
      - MYSQL_HOST=mysql
      - REDIS_HOST=redis
      - MILVUS_HOST=milvus
    depends_on:
      - mysql
      - redis
      - milvus

  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: rag_system
      MYSQL_USER: rag_user
      MYSQL_PASSWORD: ragpassword
    volumes:
      - mysql_data:/var/lib/mysql

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

  milvus:
    image: milvusdb/milvus:latest
    volumes:
      - milvus_data:/var/lib/milvus
    ports:
      - "19530:19530"

volumes:
  mysql_data:
  redis_data:
  milvus_data:
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### 1. Gunicornéƒ¨ç½²
```bash
# å®‰è£…Gunicorn
pip install gunicorn

# å¯åŠ¨APIæœåŠ¡
gunicorn api.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --access-logfile - \
  --error-logfile -
  --log-level info
```

#### 2. Nginxåå‘ä»£ç†
```nginx
server {
    listen 80;

    location /api/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /rag/ {
        proxy_pass http://127.0.0.1:8001;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

## ğŸ“š ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—é…ç½®
```python
# config/loguru_config.py
import sys
from loguru import logger

# ç§»é™¤é»˜è®¤å¤„ç†å™¨
logger.remove()

# æ·»åŠ æ–‡ä»¶å’Œæ§åˆ¶å°å¤„ç†å™¨
logger.add(
    sys.stderr,
    level="INFO",
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | <level>{message}</level>",
    rotation="1 day",
    retention="30 days"
)

# æŒ‰æ¨¡å—åˆ†ç±»å­˜å‚¨æ—¥å¿—
logger.add(
    f"logs/api/{__name__}.log",
    level="DEBUG",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} | {message}",
    rotation="1 day",
    retention="30 days",
    filter=lambda record: "api" in record["name"]
)
```

### æ€§èƒ½ç›‘æ§
```python
# infrastructure/monitoring/metrics.py
import time
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
        end_time = time.time()

        duration = end_time - start_time
        logger.info(f"Function {func.__name__} executed in {duration:.2f}s, success: {success}")

        return result
    return wrapper
```

---

è¿™ä¸ªå®æ–½æŒ‡å—æä¾›äº†è¯¦ç»†çš„æ­¥éª¤å’Œä»£ç ç¤ºä¾‹ï¼Œå¸®åŠ©ä½ ä»é›¶å¼€å§‹æ„å»ºè¿™ä¸ªRAGç³»ç»Ÿã€‚å»ºè®®æŒ‰ç…§é˜¶æ®µé¡ºåºé€æ­¥å®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µå®Œæˆåè¿›è¡Œå……åˆ†æµ‹è¯•ï¼Œç¡®ä¿åŠŸèƒ½ç¨³å®šåå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚

å¦‚æœé‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·å‚è€ƒæ•…éšœæ’é™¤éƒ¨åˆ†æˆ–æŸ¥é˜…ç›¸å…³æŠ€æœ¯æ–‡æ¡£ã€‚