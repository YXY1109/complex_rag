# ç»Ÿä¸€åµŒå…¥æœåŠ¡

## æ¦‚è¿°

ç»Ÿä¸€åµŒå…¥æœåŠ¡æ˜¯å¯¹åŸæœ‰BCEã€Qwen3ã€Genericä¸‰ä¸ªç‹¬ç«‹åµŒå…¥æœåŠ¡çš„æ•´åˆï¼Œæä¾›äº†ç»Ÿä¸€ã€é«˜æ•ˆã€å¯æ‰©å±•çš„æ–‡æœ¬åµŒå…¥è§£å†³æ–¹æ¡ˆã€‚

## ç‰¹æ€§

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½
- **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒBCEã€Qwen3ã€OpenAIç­‰å¤šç§åµŒå…¥æ¨¡å‹
- **ç»Ÿä¸€æ¥å£**: æä¾›OpenAIå…¼å®¹çš„REST APIæ¥å£
- **æ™ºèƒ½ç¼“å­˜**: å†…å­˜ç¼“å­˜æ”¯æŒï¼Œæå‡é‡å¤æŸ¥è¯¢æ€§èƒ½
- **æ‰¹é‡å¤„ç†**: é«˜æ•ˆçš„æ‰¹é‡æ–‡æœ¬åµŒå…¥å¤„ç†
- **ç”Ÿå‘½å‘¨æœŸç®¡ç†**: æ™ºèƒ½çš„æ¨¡å‹åŠ è½½å’Œå¸è½½ç®¡ç†

### ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§
- **å¯æ’æ‹”åç«¯**: æ¨¡å—åŒ–çš„æ¨¡å‹åç«¯æ¶æ„
- **å¼‚æ­¥å¤„ç†**: åŸºäºasyncioçš„å¼‚æ­¥å¤„ç†
- **è®¾å¤‡è‡ªé€‚åº”**: è‡ªåŠ¨æ£€æµ‹å’Œé€‚é…CPU/GPUè®¾å¤‡
- **å®¹é”™è®¾è®¡**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
- **ç›‘æ§å‹å¥½**: å†…ç½®å¥åº·æ£€æŸ¥å’Œæ€§èƒ½ç›‘æ§

## æ”¯æŒçš„æ¨¡å‹

### BCEåµŒå…¥æ¨¡å‹
- **æ¨¡å‹åç§°**: `bce-base`
- **ç±»å‹**: æœ¬åœ°æ¨¡å‹
- **ç»´åº¦**: 768
- **ç‰¹ç‚¹**: ä¸­æ–‡ä¼˜åŒ–ï¼Œæ€§èƒ½ä¼˜ç§€

### Qwen3åµŒå…¥æ¨¡å‹
- **æ¨¡å‹åç§°**: `qwen3-embedding`
- **ç±»å‹**: æœ¬åœ°æ¨¡å‹
- **ç»´åº¦**: 1536
- **ç‰¹ç‚¹**: é€šç”¨æ€§å¼ºï¼Œå¤šè¯­è¨€æ”¯æŒ

### OpenAIåµŒå…¥æ¨¡å‹
- **æ¨¡å‹åç§°**: `openai-text-embedding-3-small/large`
- **ç±»å‹**: äº‘ç«¯API
- **ç»´åº¦**: 1536/3072
- **ç‰¹ç‚¹**: é«˜è´¨é‡ï¼Œä»˜è´¹æœåŠ¡

## APIæ¥å£

### 1. ç”Ÿæˆæ–‡æœ¬åµŒå…¥ï¼ˆOpenAIå…¼å®¹ï¼‰

```http
POST /v1/embeddings/
```

**è¯·æ±‚ä½“**:
```json
{
    "input": "è¦åµŒå…¥çš„æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨",
    "model": "bce-base",  // å¯é€‰ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨é»˜è®¤æ¨¡å‹
    "normalize": true,      // å¯é€‰ï¼Œæ˜¯å¦å½’ä¸€åŒ–
    "use_cache": true,     // å¯é€‰ï¼Œæ˜¯å¦ä½¿ç”¨ç¼“å­˜
    "batch_size": 32       // å¯é€‰ï¼Œæ‰¹é‡å¤§å°
}
```

**å“åº”**:
```json
{
    "object": "list",
    "data": [
        {
            "object": "embedding",
            "embedding": [0.1, 0.2, ...],
            "index": 0
        }
    ],
    "model": "bce-base",
    "usage": {
        "prompt_tokens": 10,
        "total_tokens": 10
    }
}
```

### 2. è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦

```http
POST /v1/embeddings/similarity
```

**è¯·æ±‚ä½“**:
```json
{
    "text1": "ç¬¬ä¸€ä¸ªæ–‡æœ¬",
    "text2": "ç¬¬äºŒä¸ªæ–‡æœ¬",
    "model": "bce-base"  // å¯é€‰
}
```

**å“åº”**:
```json
{
    "similarity_score": 0.8542,
    "model": "bce-base",
    "processing_time": 0.045
}
```

### 3. æ‰¹é‡å¤„ç†

```http
POST /v1/embeddings/batch
```

**æŸ¥è¯¢å‚æ•°**:
- `texts`: æ–‡æœ¬åˆ—è¡¨
- `model`: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
- `batch_size`: æ‰¹é‡å¤§å°ï¼ˆå¯é€‰ï¼‰
- `use_cache`: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆå¯é€‰ï¼‰

### 4. åˆ—å‡ºå¯ç”¨æ¨¡å‹

```http
GET /v1/embeddings/models
```

**å“åº”**:
```json
{
    "object": "list",
    "data": [
        {
            "name": "bce-base",
            "type": "bce",
            "dimension": 768,
            "loaded": true,
            "is_default": true,
            "priority": 1
        }
    ]
}
```

### 5. å¥åº·æ£€æŸ¥

```http
GET /v1/embeddings/health
```

## é…ç½®

### åŸºæœ¬é…ç½®

```python
from config.unified_embedding_config import get_unified_embedding_config

config = get_unified_embedding_config()
```

### æ¨¡å‹é…ç½®ç¤ºä¾‹

```python
{
    "models": {
        "my-custom-model": {
            "model_type": "sentence_transformer",
            "model_path": "/path/to/model",
            "device": "cuda",
            "use_gpu": True,
            "dimension": 768,
            "max_length": 512,
            "batch_size": 32,
            "cache_enabled": True,
            "priority": 1
        }
    },
    "default_model": "my-custom-model"
}
```

### ç¼“å­˜é…ç½®

```python
"cache": {
    "enabled": True,
    "ttl": 3600,        // ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
    "max_size": 100000   // æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹é¢„åŠ è½½
æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨é¢„åŠ è½½é»˜è®¤æ¨¡å‹ï¼Œå‡å°‘é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿã€‚

### 2. æ™ºèƒ½ç¼“å­˜
- åŸºäºæ–‡æœ¬å†…å®¹çš„å“ˆå¸Œç¼“å­˜
- å¯é…ç½®çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
- è‡ªåŠ¨ç¼“å­˜æ¸…ç†æœºåˆ¶

### 3. æ‰¹é‡å¤„ç†ä¼˜åŒ–
- è‡ªåŠ¨æ‰¹é‡è¯·æ±‚åˆå¹¶
- å¯é…ç½®çš„æ‰¹é‡å¤§å°
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–

### 4. è®¾å¤‡ä¼˜åŒ–
- è‡ªåŠ¨æ£€æµ‹GPUå¯ç”¨æ€§
- æ™ºèƒ½å†…å­˜ç®¡ç†
- æ¨¡å‹å¸è½½/é‡è½½æœºåˆ¶

## ç›‘æ§å’Œæ—¥å¿—

### å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8000/v1/embeddings/health
```

### æ€§èƒ½æŒ‡æ ‡
- æ€»è¯·æ±‚æ•°
- ç¼“å­˜å‘½ä¸­ç‡
- å¹³å‡å¤„ç†æ—¶é—´
- æ¨¡å‹åŠ è½½ç»Ÿè®¡

### ç»“æ„åŒ–æ—¥å¿—
```python
import logging

logger = logging.getLogger("api.unified_embeddings")
logger.info("åµŒå…¥è¯·æ±‚", extra={
    "model": "bce-base",
    "text_count": 5,
    "cache_hit": True
})
```

## ä½¿ç”¨ç¤ºä¾‹

### Pythonå®¢æˆ·ç«¯

```python
import httpx
import asyncio

async def generate_embeddings():
    async with httpx.AsyncClient() as client:
        # ç”ŸæˆåµŒå…¥
        response = await client.post(
            "http://localhost:8000/v1/embeddings/",
            json={
                "input": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
                "model": "bce-base"
            }
        )
        result = response.json()
        embedding = result['data'][0]['embedding']
        return embedding

# è¿è¡Œ
embedding = asyncio.run(generate_embeddings())
print(f"åµŒå…¥å‘é‡ç»´åº¦: {len(embedding)}")
```

### æ‰¹é‡å¤„ç†

```python
async def batch_embeddings():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/v1/embeddings/batch",
            params={
                "model": "bce-base",
                "batch_size": 16
            },
            json=["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
        )
        return response.json()

results = asyncio.run(batch_embeddings())
print(f"ç”Ÿæˆäº† {len(results['embeddings'])} ä¸ªåµŒå…¥å‘é‡")
```

### ç›¸ä¼¼åº¦è®¡ç®—

```python
async def compute_similarity():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/v1/embeddings/similarity",
            json={
                "text1": "è‹¹æœ",
                "text2": "æ©™å­",
                "model": "bce-base"
            }
        )
        result = response.json()
        return result['similarity_score']

similarity = asyncio.run(compute_similarity())
print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {similarity}")
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„
   - ç¡®è®¤GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬
   - æŸ¥çœ‹æœåŠ¡æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯

2. **å†…å­˜ä¸è¶³**
   - å‡å°æ‰¹é‡å¤§å°
   - å¯ç”¨æ¨¡å‹ç¼“å­˜ç®¡ç†
   - è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹

3. **æ€§èƒ½é—®é¢˜**
   - å¯ç”¨ç¼“å­˜
   - è°ƒæ•´æ‰¹é‡å¤§å°
   - ä½¿ç”¨GPUåŠ é€Ÿ

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
docker logs -f complex-rag-unified

# æŸ¥çœ‹åµŒå…¥æœåŠ¡ç‰¹å®šæ—¥å¿—
docker logs complex-rag-unified | grep "unified_embeddings"
```

## è¿ç§»æŒ‡å—

### ä»BCEæœåŠ¡è¿ç§»

**æ—§æ¥å£**:
```http
POST /bce_embedding
```

**æ–°æ¥å£**:
```http
POST /v1/embeddings/
```

### ä»Qwen3æœåŠ¡è¿ç§»

**æ—§æ¥å£**:
```http
POST /embeddings
```

**æ–°æ¥å£**:
```http
POST /v1/embeddings/
```

### å…¼å®¹æ€§è¯´æ˜
- è¯·æ±‚æ ¼å¼å®Œå…¨å…¼å®¹OpenAIæ¥å£
- å“åº”æ ¼å¼ä¿æŒä¸€è‡´
- æ— éœ€ä¿®æ”¹ç°æœ‰å®¢æˆ·ç«¯ä»£ç 

## å¼€å‘å’Œæ‰©å±•

### æ·»åŠ æ–°çš„æ¨¡å‹åç«¯

1. ç»§æ‰¿`EmbeddingBackend`åŸºç±»
2. å®ç°å¿…è¦çš„æŠ½è±¡æ–¹æ³•
3. åœ¨ç»Ÿä¸€æœåŠ¡ä¸­æ³¨å†Œæ–°åç«¯

```python
class CustomEmbeddingBackend(EmbeddingBackend):
    async def load_model(self):
        # å®ç°æ¨¡å‹åŠ è½½
        pass

    async def embed(self, texts):
        # å®ç°åµŒå…¥ç”Ÿæˆ
        pass

    # ... å…¶ä»–å¿…è¦æ–¹æ³•
```

### è‡ªå®šä¹‰é…ç½®

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è‡ªå®šä¹‰æœåŠ¡è¡Œä¸ºï¼š

```bash
# ç¯å¢ƒå˜é‡
export EMBEDDING_DEFAULT_MODEL="qwen3-embedding"
export EMBEDDING_CACHE_TTL="7200"
export EMBEDDING_MAX_CONCURRENT="20"
```

## ç‰ˆæœ¬å†å²

- **v2.0.0**: ç»Ÿä¸€åµŒå…¥æœåŠ¡å‘å¸ƒï¼Œæ•´åˆBCEã€Qwen3ã€OpenAI
- **v1.x.x**: ç‹¬ç«‹çš„åµŒå…¥æœåŠ¡

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚