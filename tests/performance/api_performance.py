"""
APIæ€§èƒ½æµ‹è¯•
æµ‹è¯•APIå“åº”æ—¶é—´å’Œå¹¶å‘èƒ½åŠ›
"""
import asyncio
import aiohttp
import time
from typing import Dict, Any, List
from .framework import PerformanceTestFramework, BenchmarkSuite


class APIPerformanceTester:
    """APIæ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.framework = PerformanceTestFramework()

    async def test_health_endpoint(self) -> Dict[str, Any]:
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        async with aiohttp.ClientSession() as session:
            start_time = time.time()
            try:
                async with session.get(f"{self.base_url}/api/health") as response:
                    data = await response.json()
                    end_time = time.time()
                    return {
                        "success": response.status == 200,
                        "response_time": (end_time - start_time) * 1000,
                        "status_code": response.status,
                        "data": data
                    }
            except Exception as e:
                end_time = time.time()
                return {
                    "success": False,
                    "response_time": (end_time - start_time) * 1000,
                    "error": str(e)
                }

    async def test_chat_completion(self, **kwargs) -> Dict[str, Any]:
        """æµ‹è¯•èŠå¤©å®Œæˆç«¯ç‚¹"""
        default_payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "user", "content": "Hello, how are you?"}
            ],
            "temperature": 0.7,
            "max_tokens": 50
        }
        payload = {**default_payload, **kwargs}

        async with aiohttp.ClientSession() as session:
            start_time = time.time()
            try:
                async with session.post(
                    f"{self.base_url}/api/chat/completions",
                    json=payload,
                    headers={"Content-Type": "application/json"}
                ) as response:
                    if response.content_type == "application/json":
                        data = await response.json()
                    else:
                        data = await response.text()

                    end_time = time.time()
                    return {
                        "success": response.status == 200,
                        "response_time": (end_time - start_time) * 1000,
                        "status_code": response.status,
                        "data": data,
                        "payload_size": len(str(payload))
                    }
            except Exception as e:
                end_time = time.time()
                return {
                    "success": False,
                    "response_time": (end_time - start_time) * 1000,
                    "error": str(e),
                    "payload_size": len(str(payload))
                }

    async def test_document_search(self, query: str = "test", **kwargs) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡æ¡£æœç´¢ç«¯ç‚¹"""
        params = {"query": query, "limit": 10}
        params.update(kwargs)

        async with aiohttp.ClientSession() as session:
            start_time = time.time()
            try:
                async with session.get(
                    f"{self.base_url}/api/documents/search",
                    params=params
                ) as response:
                    if response.content_type == "application/json":
                        data = await response.json()
                    else:
                        data = await response.text()

                    end_time = time.time()
                    return {
                        "success": response.status == 200,
                        "response_time": (end_time - start_time) * 1000,
                        "status_code": response.status,
                        "data": data,
                        "query": query
                    }
            except Exception as e:
                end_time = time.time()
                return {
                    "success": False,
                    "response_time": (end_time - start_time) * 1000,
                    "error": str(e),
                    "query": query
                }

    async def test_knowledge_base_search(self, kb_id: str = "test-kb", query: str = "test", **kwargs) -> Dict[str, Any]:
        """æµ‹è¯•çŸ¥è¯†åº“æœç´¢ç«¯ç‚¹"""
        payload = {
            "query": query,
            "top_k": 5,
            "filters": {}
        }
        payload.update(kwargs)

        async with aiohttp.ClientSession() as session:
            start_time = time.time()
            try:
                async with session.post(
                    f"{self.base_url}/api/knowledge/bases/{kb_id}/search",
                    json=payload
                ) as response:
                    if response.content_type == "application/json":
                        data = await response.json()
                    else:
                        data = await response.text()

                    end_time = time.time()
                    return {
                        "success": response.status == 200,
                        "response_time": (end_time - start_time) * 1000,
                        "status_code": response.status,
                        "data": data,
                        "kb_id": kb_id,
                        "query": query
                    }
            except Exception as e:
                end_time = time.time()
                return {
                    "success": False,
                    "response_time": (end_time - start_time) * 1000,
                    "error": str(e),
                    "kb_id": kb_id,
                    "query": query
                }

    async def run_api_benchmark_suite(self) -> Dict[str, Any]:
        """è¿è¡ŒAPIåŸºå‡†æµ‹è¯•å¥—ä»¶"""
        print("ğŸš€ Starting API Performance Benchmark Suite")
        print(f"Target URL: {self.base_url}")

        suite = BenchmarkSuite("API_Performance_Tests")

        # æ·»åŠ å„ç§åŸºå‡†æµ‹è¯•
        suite.add_benchmark(self.test_health_endpoint, "Health_Check")
        suite.add_benchmark(self.test_chat_completion, "Chat_Completion")
        suite.add_benchmark(
            lambda: self.test_document_search("machine learning"),
            "Document_Search_ML"
        )
        suite.add_benchmark(
            lambda: self.test_knowledge_base_search("test-kb", "what is AI"),
            "Knowledge_Base_Search"
        )

        # è¿è¡Œæµ‹è¯•
        results = await suite.run_all_benchmarks(
            concurrency_levels=[1, 5, 10, 25, 50]
        )

        return results

    async def test_load_patterns(self):
        """æµ‹è¯•ä¸åŒçš„è´Ÿè½½æ¨¡å¼"""
        print("\nğŸ¯ Testing Different Load Patterns")

        # çªå‘è´Ÿè½½æµ‹è¯•
        print("\nğŸ“ˆ Testing Burst Load...")
        burst_result = await self.framework.run_concurrent_test(
            self.test_health_endpoint,
            concurrency=100,
            total_requests=500
        )

        # æŒç»­è´Ÿè½½æµ‹è¯•
        print("\nğŸ“Š Testing Sustained Load...")
        sustained_result = await self.framework.run_concurrent_test(
            self.test_health_endpoint,
            concurrency=20,
            total_requests=1000
        )

        # æ¸è¿›è´Ÿè½½æµ‹è¯•
        print("\nâ¬†ï¸ Testing Ramp-up Load...")
        rampup_results = []
        for concurrency in [5, 10, 20, 40, 80]:
            result = await self.framework.run_concurrent_test(
                self.test_health_endpoint,
                concurrency=concurrency,
                total_requests=concurrency * 10
            )
            rampup_results.append({
                'concurrency': concurrency,
                'result': result
            })

        return {
            'burst_load': burst_result,
            'sustained_load': sustained_result,
            'rampup_load': rampup_results
        }

    async def test_api_limits(self):
        """æµ‹è¯•APIé™åˆ¶å’Œè¾¹ç•Œæ¡ä»¶"""
        print("\nğŸš§ Testing API Limits and Boundaries")

        # æµ‹è¯•å¤§è¯·æ±‚è´Ÿè½½
        print("\nğŸ“ Testing Large Payload...")
        large_payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "user", "content": "A" * 10000}  # 10KB content
            ],
            "max_tokens": 100
        }

        large_payload_result = await self.framework.run_concurrent_test(
            lambda: self.test_chat_completion(**large_payload),
            concurrency=5,
            total_requests=50
        )

        # æµ‹è¯•å¿«é€Ÿè¿ç»­è¯·æ±‚
        print("\nâš¡ Testing Rapid Fire Requests...")
        rapid_result = await self.framework.run_concurrent_test(
            self.test_health_endpoint,
            concurrency=1,
            total_requests=1000
        )

        # æµ‹è¯•å¹¶å‘é™åˆ¶
        print("\nğŸ”’ Testing Concurrency Limits...")
        concurrency_result = await self.framework.run_concurrent_test(
            self.test_health_endpoint,
            concurrency=200,
            total_requests=1000
        )

        return {
            'large_payload': large_payload_result,
            'rapid_fire': rapid_result,
            'concurrency_limit': concurrency_result
        }

    async def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†æ€§èƒ½"""
        print("\nâŒ Testing Error Handling Performance")

        # æµ‹è¯•æ— æ•ˆç«¯ç‚¹
        async def test_invalid_endpoint():
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                try:
                    async with session.get(f"{self.base_url}/api/invalid-endpoint") as response:
                        end_time = time.time()
                        return {
                            "success": False,
                            "response_time": (end_time - start_time) * 1000,
                            "status_code": response.status
                        }
                except Exception as e:
                    end_time = time.time()
                    return {
                        "success": False,
                        "response_time": (end_time - start_time) * 1000,
                        "error": str(e)
                    }

        # æµ‹è¯•æ— æ•ˆè´Ÿè½½
        async def test_invalid_payload():
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                try:
                    async with session.post(
                        f"{self.base_url}/api/chat/completions",
                        json={"invalid": "payload"},
                        headers={"Content-Type": "application/json"}
                    ) as response:
                        end_time = time.time()
                        return {
                            "success": False,
                            "response_time": (end_time - start_time) * 1000,
                            "status_code": response.status
                        }
                except Exception as e:
                    end_time = time.time()
                    return {
                        "success": False,
                        "response_time": (end_time - start_time) * 1000,
                        "error": str(e)
                    }

        # è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•
        invalid_endpoint_result = await self.framework.run_concurrent_test(
            test_invalid_endpoint,
            concurrency=20,
            total_requests=100
        )

        invalid_payload_result = await self.framework.run_concurrent_test(
            test_invalid_payload,
            concurrency=20,
            total_requests=100
        )

        return {
            'invalid_endpoint': invalid_endpoint_result,
            'invalid_payload': invalid_payload_result
        }

    def generate_performance_report(self, all_results: Dict[str, Any]):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print("\nğŸ“Š Generating Performance Report...")

        report = {
            "test_summary": {
                "total_tests": len(all_results),
                "timestamp": time.time(),
                "base_url": self.base_url
            },
            "results": {}
        }

        # å¤„ç†å„ç§æµ‹è¯•ç»“æœ
        for test_name, result in all_results.items():
            if hasattr(result, 'test_name'):  # BenchmarkResult
                report["results"][test_name] = {
                    "avg_response_time": result.avg_response_time,
                    "p95_response_time": result.p95_response_time,
                    "requests_per_second": result.requests_per_second,
                    "success_rate": result.success_rate,
                    "max_cpu": result.metadata.get('resource_usage', {}).get('cpu', {}).get('max', 0),
                    "max_memory": result.metadata.get('resource_usage', {}).get('memory', {}).get('max', 0)
                }
            elif isinstance(result, dict):  # å¤åˆç»“æœ
                report["results"][test_name] = {}
                for sub_test, sub_result in result.items():
                    if hasattr(sub_result, 'test_name'):
                        report["results"][test_name][sub_test] = {
                            "avg_response_time": sub_result.avg_response_time,
                            "requests_per_second": sub_result.requests_per_second,
                            "success_rate": sub_result.success_rate
                        }

        # ä¿å­˜æŠ¥å‘Š
        import json
        from pathlib import Path

        report_path = f"tests/performance/reports/api_performance_{int(time.time())}.json"
        Path(report_path).parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“‹ Performance report saved to: {report_path}")

        # æ‰“å°æ‘˜è¦
        self._print_performance_summary(report)

        return report_path

    def _print_performance_summary(self, report: Dict):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        print(f"\n{'='*80}")
        print("ğŸ“Š API Performance Summary")
        print(f"{'='*80}")

        results = report.get("results", {})
        if not results:
            print("No results to display")
            return

        print(f"{'Test Name':<30} {'RPS':<8} {'Avg RT':<8} {'P95 RT':<8} {'Success':<8} {'Max CPU':<8} {'Max Mem':<8}")
        print(f"{'-'*80}")

        for test_name, metrics in results.items():
            if "avg_response_time" in metrics:
                print(f"{test_name[:30]:<30} "
                      f"{metrics.get('requests_per_second', 0):<8.1f} "
                      f"{metrics.get('avg_response_time', 0):<8.1f} "
                      f"{metrics.get('p95_response_time', 0):<8.1f} "
                      f"{metrics.get('success_rate', 0):<8.1%} "
                      f"{metrics.get('max_cpu', 0):<8.1f} "
                      f"{metrics.get('max_memory', 0):<8.1f}")

        print(f"\n{'='*80}")


# ä¾¿æ·å‡½æ•°
async def run_api_performance_tests(base_url: str = "http://localhost:8000"):
    """è¿è¡ŒAPIæ€§èƒ½æµ‹è¯•çš„ä¸»å‡½æ•°"""
    tester = APIPerformanceTester(base_url)

    print("ğŸ¯ Starting Comprehensive API Performance Tests")
    print(f"Target: {base_url}")

    # 1. åŸºå‡†æµ‹è¯•å¥—ä»¶
    benchmark_results = await tester.run_api_benchmark_suite()

    # 2. è´Ÿè½½æ¨¡å¼æµ‹è¯•
    load_results = await tester.test_load_patterns()

    # 3. é™åˆ¶æµ‹è¯•
    limits_results = await tester.test_api_limits()

    # 4. é”™è¯¯å¤„ç†æµ‹è¯•
    error_results = await tester.test_error_handling()

    # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    all_results = {
        "benchmark_suite": benchmark_results,
        "load_patterns": load_results,
        "api_limits": limits_results,
        "error_handling": error_results
    }

    report_path = tester.generate_performance_report(all_results)

    return all_results, report_path