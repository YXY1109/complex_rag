"""
å¼‚æ­¥ä»»åŠ¡æ€§èƒ½æµ‹è¯•
æµ‹è¯•å¼‚æ­¥ä»»åŠ¡å¤„ç†æ€§èƒ½
"""
import asyncio
import time
import json
from typing import Dict, Any, List, Callable
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from .framework import PerformanceTestFramework, BenchmarkSuite


@dataclass
class AsyncTaskResult:
    """å¼‚æ­¥ä»»åŠ¡ç»“æœ"""
    task_id: str
    start_time: float
    end_time: float
    duration: float  # æ¯«ç§’
    success: bool
    result: Any = None
    error: str = None
    worker_id: int = None


class AsyncTaskPerformanceTester:
    """å¼‚æ­¥ä»»åŠ¡æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self):
        self.framework = PerformanceTestFramework()
        self.thread_pool = ThreadPoolExecutor(max_workers=100)
        self.results: List[AsyncResult] = []

    async def create_test_task(self, task_id: str, duration: float = 0.1, cpu_intensive: bool = False) -> AsyncTaskResult:
        """åˆ›å»ºæµ‹è¯•ä»»åŠ¡"""
        start_time = time.time()

        try:
            if cpu_intensive:
                # CPUå¯†é›†å‹ä»»åŠ¡
                result = await self._cpu_intensive_task(duration)
            else:
                # IOå¯†é›†å‹ä»»åŠ¡
                result = await self._io_intensive_task(duration)

            end_time = time.time()
            return AsyncTaskResult(
                task_id=task_id,
                start_time=start_time,
                end_time=end_time,
                duration=(end_time - start_time) * 1000,
                success=True,
                result=result
            )
        except Exception as e:
            end_time = time.time()
            return AsyncTaskResult(
                task_id=task_id,
                start_time=start_time,
                end_time=end_time,
                duration=(end_time - start_time) * 1000,
                success=False,
                error=str(e)
            )

    async def _io_intensive_task(self, duration: float) -> str:
        """IOå¯†é›†å‹ä»»åŠ¡æ¨¡æ‹Ÿ"""
        await asyncio.sleep(duration)
        return f"IO task completed in {duration}s"

    async def _cpu_intensive_task(self, duration: float) -> int:
        """CPUå¯†é›†å‹ä»»åŠ¡æ¨¡æ‹Ÿ"""
        # è®¡ç®—å¯†é›†å‹æ“ä½œ
        result = 0
        start = time.time()
        while time.time() - start < duration:
            result += sum(i * i for i in range(1000))
        return result

    async def test_async_task_creation(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡åˆ›å»ºæ€§èƒ½"""
        task_count = 1000
        tasks = []

        start_time = time.time()

        # åˆ›å»ºå¤§é‡å¼‚æ­¥ä»»åŠ¡
        for i in range(task_count):
            task = asyncio.create_task(
                self.create_test_task(f"task_{i}", 0.01)
            )
            tasks.append(task)

        creation_time = time.time() - start_time

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        completion_time = time.time() - start_time

        # åˆ†æç»“æœ
        successful_tasks = [r for r in results if isinstance(r, AsyncTaskResult) and r.success]
        failed_tasks = [r for r in results if isinstance(r, AsyncTaskResult) and not r.success]

        return {
            "task_count": task_count,
            "creation_time": creation_time,
            "creation_rate": task_count / creation_time,
            "completion_time": completion_time,
            "completion_rate": len(successful_tasks) / completion_time,
            "successful_tasks": len(successful_tasks),
            "failed_tasks": len(failed_tasks),
            "success_rate": len(successful_tasks) / task_count,
            "avg_task_duration": sum(r.duration for r in successful_tasks) / len(successful_tasks) if successful_tasks else 0
        }

    async def test_async_task_concurrency(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡å¹¶å‘æ€§èƒ½"""
        concurrency_levels = [10, 50, 100, 500, 1000]
        results = {}

        for concurrency in concurrency_levels:
            print(f"Testing with {concurrency} concurrent tasks...")

            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = [
                self.create_test_task(f"task_{i}", 0.1)
                for i in range(concurrency)
            ]

            start_time = time.time()
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            end_time = time.time()

            # åˆ†æç»“æœ
            successful = [r for r in task_results if isinstance(r, AsyncTaskResult) and r.success]
            failed = [r for r in task_results if isinstance(r, AsyncTaskResult) and not r.success]

            if successful:
                durations = [r.duration for r in successful]
                results[concurrency] = {
                    "total_time": end_time - start_time,
                    "successful_tasks": len(successful),
                    "failed_tasks": len(failed),
                    "success_rate": len(successful) / concurrency,
                    "avg_duration": sum(durations) / len(durations),
                    "min_duration": min(durations),
                    "max_duration": max(durations),
                    "throughput": len(successful) / (end_time - start_time)
                }
            else:
                results[concurrency] = {
                    "total_time": end_time - start_time,
                    "successful_tasks": 0,
                    "failed_tasks": len(failed),
                    "success_rate": 0.0,
                    "throughput": 0.0
                }

        return results

    async def test_async_queue_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥é˜Ÿåˆ—å¤„ç†æ€§èƒ½"""
        queue_size = 1000
        task_duration = 0.01
        worker_count = 10

        # åˆ›å»ºå¼‚æ­¥é˜Ÿåˆ—
        queue = asyncio.Queue(maxsize=queue_size * 2)

        # ç”Ÿäº§è€…ä»»åŠ¡
        async def producer():
            for i in range(queue_size):
                await queue.put(f"task_{i}")

        # æ¶ˆè´¹è€…ä»»åŠ¡
        async def consumer(worker_id: int):
            processed = 0
            while True:
                try:
                    task_id = queue.get_nowait()
                    # å¤„ç†ä»»åŠ¡
                    await asyncio.sleep(task_duration)
                    processed += 1
                    queue.task_done()
                except asyncio.QueueEmpty:
                    break
            return processed

        start_time = time.time()

        # å¯åŠ¨ç”Ÿäº§è€…
        producer_task = asyncio.create_task(producer())

        # ç­‰å¾…ç”Ÿäº§è€…å®Œæˆ
        await producer_task

        # å¯åŠ¨æ¶ˆè´¹è€…
        consumer_tasks = [
            asyncio.create_task(consumer(i))
            for i in range(worker_count)
        ]

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡è¢«å¤„ç†
        await queue.join()

        # è·å–æ¶ˆè´¹è€…ç»“æœ
        consumer_results = await asyncio.gather(*consumer_tasks)

        end_time = time.time()
        total_processed = sum(consumer_results)

        return {
            "queue_size": queue_size,
            "worker_count": worker_count,
            "total_time": end_time - start_time,
            "total_processed": total_processed,
            "processing_rate": total_processed / (end_time - start_time),
            "avg_tasks_per_worker": total_processed / worker_count,
            "success_rate": total_processed / queue_size
        }

    async def test_async_semaphore_limiting(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä¿¡å·é‡é™åˆ¶æ€§èƒ½"""
        total_tasks = 500
        semaphore_limits = [10, 25, 50, 100, 200]
        results = {}

        for limit in semaphore_limits:
            print(f"Testing semaphore limit: {limit}")

            semaphore = asyncio.Semaphore(limit)

            async def limited_task(task_id: int):
                async with semaphore:
                    return await self.create_test_task(f"task_{task_id}", 0.05)

            start_time = time.time()

            tasks = [limited_task(i) for i in range(total_tasks)]
            task_results = await asyncio.gather(*tasks, return_exceptions=True)

            end_time = time.time()

            # åˆ†æç»“æœ
            successful = [r for r in task_results if isinstance(r, AsyncTaskResult) and r.success]
            failed = [r for r in task_results if isinstance(r, AsyncTaskResult) and not r.success]

            if successful:
                durations = [r.duration for r in successful]
                results[limit] = {
                    "total_time": end_time - start_time,
                    "successful_tasks": len(successful),
                    "failed_tasks": len(failed),
                    "success_rate": len(successful) / total_tasks,
                    "avg_duration": sum(durations) / len(durations),
                    "throughput": len(successful) / (end_time - start_time)
                }
            else:
                results[limit] = {
                    "total_time": end_time - start_time,
                    "successful_tasks": 0,
                    "failed_tasks": len(failed),
                    "success_rate": 0.0,
                    "throughput": 0.0
                }

        return results

    async def test_async_event_driven_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•äº‹ä»¶é©±åŠ¨å¼‚æ­¥å¤„ç†æ€§èƒ½"""
        event_count = 1000
        events_processed = 0

        # åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—
        event_queue = asyncio.Queue()

        # äº‹ä»¶å¤„ç†å™¨
        async def event_handler():
            nonlocal events_processed
            while True:
                try:
                    event = event_queue.get_nowait()
                    # æ¨¡æ‹Ÿäº‹ä»¶å¤„ç†
                    await asyncio.sleep(0.001)  # 1mså¤„ç†æ—¶é—´
                    events_processed += 1
                    event_queue.task_done()
                except asyncio.QueueEmpty:
                    break

        start_time = time.time()

        # ç”Ÿäº§äº‹ä»¶
        for i in range(event_count):
            await event_queue.put({
                "id": i,
                "type": "test_event",
                "data": f"event_data_{i}",
                "timestamp": time.time()
            })

        # å¯åŠ¨äº‹ä»¶å¤„ç†å™¨
        handler_task = asyncio.create_task(event_handler())

        # ç­‰å¾…æ‰€æœ‰äº‹ä»¶è¢«å¤„ç†
        await event_queue.join()
        await handler_task

        end_time = time.time()

        return {
            "event_count": event_count,
            "events_processed": events_processed,
            "processing_time": end_time - start_time,
            "processing_rate": events_processed / (end_time - start_time),
            "success_rate": events_processed / event_count
        }

    async def test_async_batch_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥æ‰¹å¤„ç†æ€§èƒ½"""
        total_items = 1000
        batch_sizes = [10, 50, 100, 200]
        results = {}

        for batch_size in batch_sizes:
            print(f"Testing batch size: {batch_size}")

            # åˆ†æ‰¹å¤„ç†
            batches = [
                list(range(i, min(i + batch_size, total_items)))
                for i in range(0, total_items, batch_size)
            ]

            start_time = time.time()

            batch_results = []
            for batch in batches:
                # å¹¶å‘å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
                batch_tasks = [
                    self.create_test_task(f"item_{item}", 0.001)
                    for item in batch
                ]
                batch_result = await asyncio.gather(*batch_tasks, return_exceptions=True)
                batch_results.extend(batch_result)

            end_time = time.time()

            # åˆ†æç»“æœ
            successful = [r for r in batch_results if isinstance(r, AsyncTaskResult) and r.success]
            failed = [r for r in batch_results if isinstance(r, AsyncTaskResult) and not r.success]

            if successful:
                durations = [r.duration for r in successful]
                results[batch_size] = {
                    "batch_count": len(batches),
                    "total_time": end_time - start_time,
                    "successful_items": len(successful),
                    "failed_items": len(failed),
                    "success_rate": len(successful) / total_items,
                    "avg_duration": sum(durations) / len(durations),
                    "throughput": len(successful) / (end_time - start_time)
                }
            else:
                results[batch_size] = {
                    "batch_count": len(batches),
                    "total_time": end_time - start_time,
                    "successful_items": 0,
                    "failed_items": len(failed),
                    "success_rate": 0.0,
                    "throughput": 0.0
                }

        return results

    async def test_async_memory_efficiency(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡å†…å­˜æ•ˆç‡"""
        import psutil

        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # åˆ›å»ºå¤§é‡å¼‚æ­¥ä»»åŠ¡ä½†å»¶è¿Ÿæ‰§è¡Œ
        task_count = 10000
        tasks = []

        start_time = time.time()

        # åˆ›å»ºä»»åŠ¡ä½†ä¸ç«‹å³æ‰§è¡Œ
        for i in range(task_count):
            task = asyncio.create_task(
                self.create_test_task(f"memory_task_{i}", 0.001)
            )
            tasks.append(task)

            # æ¯1000ä¸ªä»»åŠ¡æ£€æŸ¥ä¸€æ¬¡å†…å­˜
            if i % 1000 == 0:
                current_memory = process.memory_info().rss / 1024 / 1024
                print(f"  Created {i} tasks, memory: {current_memory:.2f}MB")

        creation_memory = process.memory_info().rss / 1024 / 1024

        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ç­‰å¾…åƒåœ¾å›æ”¶
        await asyncio.sleep(1)

        final_memory = process.memory_info().rss / 1024 / 1024

        end_time = time.time()

        # åˆ†æç»“æœ
        successful = [r for r in results if isinstance(r, AsyncTaskResult) and r.success]

        return {
            "task_count": task_count,
            "initial_memory_mb": initial_memory,
            "creation_memory_mb": creation_memory,
            "final_memory_mb": final_memory,
            "peak_memory_mb": max(creation_memory, final_memory),
            "memory_growth_mb": final_memory - initial_memory,
            "memory_per_task_kb": (final_memory - initial_memory) * 1024 / task_count,
            "total_time": end_time - start_time,
            "successful_tasks": len(successful),
            "success_rate": len(successful) / task_count
        }

    async def run_async_performance_suite(self) -> Dict[str, Any]:
        """è¿è¡Œå¼‚æ­¥æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
        print("ğŸš€ Starting Async Task Performance Tests")

        # 1. ä»»åŠ¡åˆ›å»ºæ€§èƒ½
        print("\nğŸ“ Testing task creation performance...")
        creation_result = await self.test_async_task_creation()

        # 2. å¹¶å‘æ€§èƒ½
        print("\nğŸ”€ Testing concurrency performance...")
        concurrency_result = await self.test_async_task_concurrency()

        # 3. é˜Ÿåˆ—å¤„ç†æ€§èƒ½
        print("\nğŸ“‹ Testing queue processing performance...")
        queue_result = await self.test_async_queue_processing()

        # 4. ä¿¡å·é‡é™åˆ¶æ€§èƒ½
        print("\nğŸš¦ Testing semaphore limiting performance...")
        semaphore_result = await self.test_async_semaphore_limiting()

        # 5. äº‹ä»¶é©±åŠ¨å¤„ç†æ€§èƒ½
        print("\nâš¡ Testing event-driven processing performance...")
        event_result = await self.test_async_event_driven_processing()

        # 6. æ‰¹å¤„ç†æ€§èƒ½
        print("\nğŸ“¦ Testing batch processing performance...")
        batch_result = await self.test_async_batch_processing()

        # 7. å†…å­˜æ•ˆç‡æµ‹è¯•
        print("\nğŸ’¾ Testing memory efficiency...")
        memory_result = await self.test_async_memory_efficiency()

        return {
            "task_creation": creation_result,
            "concurrency": concurrency_result,
            "queue_processing": queue_result,
            "semaphore_limiting": semaphore_result,
            "event_driven": event_result,
            "batch_processing": batch_result,
            "memory_efficiency": memory_result
        }

    def generate_async_performance_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆå¼‚æ­¥æ€§èƒ½æŠ¥å‘Š"""
        print("\nğŸ“Š Generating Async Performance Report...")

        report = {
            "test_summary": {
                "timestamp": time.time(),
                "total_tests": len(results)
            },
            "results": results
        }

        # ä¿å­˜æŠ¥å‘Š
        import json
        from pathlib import Path

        report_path = f"tests/performance/reports/async_performance_{int(time.time())}.json"
        Path(report_path).parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“‹ Async performance report saved to: {report_path}")

        # æ‰“å°æ‘˜è¦
        self._print_async_performance_summary(results)

        return report_path

    def _print_async_performance_summary(self, results: Dict):
        """æ‰“å°å¼‚æ­¥æ€§èƒ½æ‘˜è¦"""
        print(f"\n{'='*80}")
        print("ğŸ“Š Async Task Performance Summary")
        print(f"{'='*80}")

        # ä»»åŠ¡åˆ›å»ºæ‘˜è¦
        if "task_creation" in results:
            creation = results["task_creation"]
            print(f"\nğŸ“ Task Creation:")
            print(f"  Creation Rate: {creation.get('creation_rate', 0):.2f} tasks/sec")
            print(f"  Completion Rate: {creation.get('completion_rate', 0):.2f} tasks/sec")
            print(f"  Success Rate: {creation.get('success_rate', 0):.2%}")

        # å¹¶å‘æ€§èƒ½æ‘˜è¦
        if "concurrency" in results:
            concurrency = results["concurrency"]
            print(f"\nğŸ”€ Concurrency Performance:")
            print(f"{'Concurrency':<12} {'Throughput':<12} {'Success Rate':<12} {'Avg Duration':<12}")
            print(f"{'-'*50}")
            for level, metrics in concurrency.items():
                print(f"{level:<12} "
                      f"{metrics.get('throughput', 0):<12.1f} "
                      f"{metrics.get('success_rate', 0):<12.1%} "
                      f"{metrics.get('avg_duration', 0):<12.1f}")

        # é˜Ÿåˆ—å¤„ç†æ‘˜è¦
        if "queue_processing" in results:
            queue = results["queue_processing"]
            print(f"\nğŸ“‹ Queue Processing:")
            print(f"  Processing Rate: {queue.get('processing_rate', 0):.2f} tasks/sec")
            print(f"  Success Rate: {queue.get('success_rate', 0):.2%}")
            print(f"  Avg Tasks per Worker: {queue.get('avg_tasks_per_worker', 0):.1f}")

        # å†…å­˜æ•ˆç‡æ‘˜è¦
        if "memory_efficiency" in results:
            memory = results["memory_efficiency"]
            print(f"\nğŸ’¾ Memory Efficiency:")
            print(f"  Memory Growth: {memory.get('memory_growth_mb', 0):.2f}MB")
            print(f"  Memory per Task: {memory.get('memory_per_task_kb', 0):.2f}KB")
            print(f"  Success Rate: {memory.get('success_rate', 0):.2%}")

        print(f"\n{'='*80}")


# ä¾¿æ·å‡½æ•°
async def run_async_performance_tests():
    """è¿è¡Œå¼‚æ­¥æ€§èƒ½æµ‹è¯•çš„ä¸»å‡½æ•°"""
    tester = AsyncTaskPerformanceTester()

    print("ğŸ¯ Starting Comprehensive Async Performance Tests")

    # è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶
    results = await tester.run_async_performance_suite()

    # ç”ŸæˆæŠ¥å‘Š
    report_path = tester.generate_async_performance_report(results)

    return results, report_path